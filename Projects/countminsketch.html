<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Count‑Min Sketch – Randomized Algorithms – Masrur Chowdhury</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="../style.css" />
</head>
<body>
  <nav class="navbar">
    <a href="../index.html">← Back to Home</a>
  </nav>

  <main>
    <h1>Count‑Min Sketch (CMS): Streaming Word Frequency Estimation</h1>

    <p>
      For a randomized algorithms project at Middlebury, I implemented a <strong>Count‑Min Sketch</strong> to estimate
      word frequencies in large text streams. I used it on long English text files and surfaced the most
      frequent words quickly, with a small, fixed memory footprint.
    </p>

    <h2>What I Built</h2>
    <ul>
      <li><strong>Pipeline:</strong> read → normalize (lowercase, strip punctuation) → tokenize → stream through CMS → report top‑k.</li>
      <li><strong>Sketch layout:</strong> a small <em>d × w</em> counter table; I used <strong>w ≈ 397</strong> (prime width) and <strong>d = 3</strong> rows.</li>
      <li><strong>Hashing:</strong> three independent hash functions via distinct seeds over a fast string hash.</li>
      <li><strong>Top‑k tracking:</strong> maintained a tiny heap of candidate heavy hitters while streaming.</li>
      <li><strong>Validation:</strong> compared sketch estimates to exact counts on samples / final pass to confirm top entries.</li>
    </ul>

    <h2>How CMS Works (brief)</h2>
    <p>
      A CMS is a compact table of counters with <strong>d</strong> rows and <strong>w</strong> columns. Each incoming token is hashed
      with <strong>d</strong> independent hash functions—one per row—and we increment the corresponding counters. The
      estimated count of a token is the <em>minimum</em> of those <strong>d</strong> counters, which limits overestimation caused by collisions.
    </p>

    <figure style="text-align:center;">
      <img src="../images/countminsketch.png"
           alt="Count‑Min Sketch diagram: multiple hash functions mapping a word to d counters"
           style="width:100%; max-width:680px; display:block; margin:20px auto; border-radius:8px;">
      <figcaption style="font-size:.85em; color:gray;">
        Stylized CMS layout I used (illustrative).
      </figcaption>
    </figure>

    <h2>Practical Choices &amp; Trade‑offs</h2>
    <ul>
      <li><strong>Table size:</strong> I chose a <em>prime</em> width (~397) to spread hashes well without using much memory.</li>
      <li><strong>Depth:</strong> 3 rows was enough to stabilize estimates and keep updates fast.</li>
      <li><strong>Speed/memory:</strong> O(1)‑like update and query per row; fixed memory regardless of unique vocabulary.</li>
      <li><strong>Post‑processing:</strong> used a small heap to keep likely top words without scanning everything again.</li>
    </ul>

    <h2>Results</h2>
    <ul class="project-results">
      <li>Identified the most frequent words in multi‑MB inputs in ~<strong>1–2 seconds</strong> on a laptop.</li>
      <li>Matched exact counts on the top words we checked (heavy hitters), while using a fixed‑size sketch.</li>
      <li>Handled long inputs without storing a counter per distinct word.</li>
    </ul>

    <h2>Notes &amp; Extensions</h2>
    <ul>
      <li>Swap in different hash seeds or widen the table for noisier corpora.</li>
      <li>Optionally remove stop‑words or apply stemming if you care about semantics.</li>
      <li>For small inputs, a hashmap is fine; CMS shines when inputs get large or streaming.</li>
    </ul>

    <p style="font-style:italic; color:gray;">
      This page reflects my implementation and tests. Diagrams are illustrative; numbers are from my runs and sanity checks.
    </p>

    <p><a href="../index.html#work">← Back to Selected Work</a></p>
  </main>

  <footer>
    <p>&copy; 2025 Masrur Chowdhury</p>
  </footer>
</body>
</html>

</body>
</html>
